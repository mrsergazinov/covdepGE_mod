---
title: "Project Results"
author: "Isaac Ray, Renat Sergazinov, GÃ¶zde Sert"
format: 
  pdf:
    include-in-header:
      - preamble.tex
      - text: |
          \addtokomafont{disposition}{\rmfamily}
editor: visual
bibliography: references.bib
---

```{r setup, include=FALSE}
library(covdepGE)
library(tidyverse)
library(purrr)
library(Matrix)
library(xtable)
```

# Background

# Problem

Despite this model demonstrating superior sensitivity to true dependence relations than competing methods, it suffers from lower specificity. Compared with competing methods from the `mgm` [@mgm] and `JGL` [@JGL]packages, the specificity gets substantially worse as the number of features increases. In the case of analyzing gene expression data, this could lead to worse outcomes than a less sensitive and more specific model since the cost of carrying out experiments which show a lack of a predicted relation may be very expensive. Further, validating a true but relatively weak relationship may not be desirable considering the cost. Ideally we want to **increase the specificity of the model without substantially hurting the model's sensitivity and speed**.

# Attempted Solutions

We'll look at a variety of different modifications to the algorithm in order of least to most extensive changes necessary, and use the `covdepGE` package[@covdepGE] in order to generate data for simulation studies. For some of these solutions, the package's functions will be used without modification and changes will occur outside of the inference algorithm. Otherwise, any changes to the functions will be explicitly noted.

In general, we expect that the underlying cause of the specificity issue is due to having a common prior inclusion probability $\pi$ across every spike-and-slab regression being performed despite the varying values of $Z$ (and potentially $X$). We may expect that for certain values of $Z$, we have a different belief about whether variables in $X$ are related. We'll approach this from 2 angles; first by trying to modify our variables and covariates in such a way as to make a common $\pi$ a more appropriate choice, and then by modifying the algorithm to allow for multiple $\pi$ values to be specified either a priori or as a function $\pi(X,Z)$ through something like clustering.

## Feature Scaling Changes

The first approach will be to use a different or additional approach to feature scaling on $X$ and/or $Z$ in order to try and make a singular prior inclusion probability more appropriate.

### Existing Feature Scaling through Normalization

Currently, the default behavior in the `covdepGE` function is to perform a columnwise Z-score Normalization on $Z$ and a columnwise 0 centering on $X$. For brevity we'll denote this procedure by "normalization". The baseline performance under this scheme is given below. All experiments were run under 4 different setups each having different values for $p$ and $n$, and data simulated using the `generateData` function. To assess sensitivity and specificity, we'll examine the number of false positives per sample and number of false negatives per sample across 100 replications of each simulation setup. So, in all cases lower numbers are desirable. First, we'll look at the baseline performance of the existing function with no changes to the default behavior.

```{r baseline-sims, include=FALSE, cache = TRUE}
# Utility function for tables
meanAndSdStr = function(x) {
  string = c(paste0(round(mean(x),2)," (", round(sd(x),2), ")"))
  return(string)
}


# Load in simulation studies

# Not doing the p100 n300 case since a single simulation
# requires over 16 hours on the cluster and many simulations
# need to be done

p = c(5, 15, 25, 50) %>% as.integer()
n = c(90, 90, 150, 150) %>% as.integer()
objects_strings = c(
  "simulation_study//p5_n90//res_p5_n90_covdepGE_20220908_215120.Rda",
  "simulation_study//p15_n90//res_p15_n90_covdepGE_20220908_215229.Rda",
  "simulation_study//p25_n150//res_p25_n150_covdepGE_20220825_121750.Rda",
  "simulation_study//p50_n150//res_p50_n150_covdepGE_20220825_090326.Rda"
  # "simulation_study//p100_n300//res_p100_n300_covdepGE_20220824_084919.Rda"
)

results_original = list()
for(sim in 1:length(objects_strings)) {
  load(objects_strings[sim])
  results_original[[sim]] = results
  rm(results)
}
sim_names_original = paste0("p", p, "_n", n)
results_original = set_names(results_original, sim_names_original)

false_positives_baseline = results_original %>%
  map(function(x)
    map_dbl(x, pluck, "FP_n")
  )
false_negatives_baseline = results_original %>%
  map(function(x)
    map_dbl(x, pluck, "FN_n")
  )

fp_baseline_str = false_positives_baseline %>% 
  map_chr(meanAndSdStr) %>% 
  data.frame(string = .) %>%
  rename("Baseline Mean (sd)" = string)

fn_baseline_str = false_negatives_baseline %>% 
  map_chr(meanAndSdStr) %>% 
  data.frame(string = .) %>%
  rename("Baseline Mean (sd)" = string)

fp_xtable_baseline = fp_baseline_str %>%
  cbind(p, n, .) %>%
  tibble() %>%
  xtable(caption = "False \\textbf{positives} per sample - Normalized Z, Centered X")

fn_xtable_baseline = fn_baseline_str %>%
  cbind(p, n, .) %>%
  tibble() %>%
  xtable("False \\textbf{negatives} per sample - Normalized Z, Centered X")

rm(results_original)
```

```{r print-baseline-xtable, results='asis', echo=FALSE}
print(fp_xtable_baseline, 
      comment=FALSE, 
      include.rownames = FALSE,
      table.placement = "H")
print(fn_xtable_baseline, 
      comment=FALSE, 
      include.rownames = FALSE,
      table.placement = "H")
```

### Max-Min Feature Scaling

```{r min-max-only-sims, include=FALSE, cache = TRUE}
load("minmax_Z_sim.Rda")

fp_xtable_mmZ = min_max_Z_simulation_results %>%
  map(function(x)
    map_dbl(x, pluck, "FP_n")
  ) %>% 
  map_chr(meanAndSdStr) %>% 
  data.frame(string = .) %>%
  rename("Mean (sd)" = string) %>%
  cbind(p, n, fp_baseline_str, .) %>%
  tibble() %>%
  xtable(caption = "False \\textbf{positives} per sample - Max/Min Scaled Z")

fn_xtable_mmZ = min_max_Z_simulation_results %>%
  map(function(x)
    map_dbl(x, pluck, "FN_n")
  ) %>% 
  map_chr(meanAndSdStr) %>% 
  data.frame(string = .) %>%
  rename("Mean (sd)" = string) %>%
  cbind(p, n, fn_baseline_str, .) %>%
  tibble() %>%
  xtable(caption = "False \\textbf{negatives} per sample - Max/Min Scaled Z")

rm(min_max_Z_simulation_results)

load("minmax_X_sim.Rda")

fp_xtable_mmX = min_max_X_simulation_results %>%
  map(function(x)
    map_dbl(x, pluck, "FP_n")
  ) %>% 
  map_chr(meanAndSdStr) %>% 
  data.frame(string = .) %>%
  rename("Mean (sd)" = string) %>%
  cbind(p, n, fp_baseline_str, .) %>%
  tibble() %>%
  xtable(caption = "False \\textbf{positives} per sample - Max/Min Scaled X")

fn_xtable_mmX = min_max_X_simulation_results %>%
  map(function(x)
    map_dbl(x, pluck, "FN_n")
  ) %>% 
  map_chr(meanAndSdStr) %>% 
  data.frame(string = .) %>%
  rename("Mean (sd)" = string) %>%
  cbind(p, n, fn_baseline_str, .) %>%
  tibble() %>%
  xtable(caption = "False \\textbf{negatives} per sample - Max/Min Scaled X")

rm(min_max_X_simulation_results)

load("minmax_XZ_sim.Rda")

fp_xtable_mmXZ = min_max_XZ_simulation_results %>%
  map(function(x)
    map_dbl(x, pluck, "FP_n")
  ) %>% 
  map_chr(meanAndSdStr) %>% 
  data.frame(string = .) %>%
  rename("Mean (sd)" = string) %>%
  cbind(p, n, fp_baseline_str, .) %>%
  tibble() %>%
  xtable(caption = "False \\textbf{positives} per sample - Max/Min Scaled X and Z")

fn_xtable_mmXZ = min_max_XZ_simulation_results %>%
  map(function(x)
    map_dbl(x, pluck, "FN_n")
  ) %>% 
  map_chr(meanAndSdStr) %>% 
  data.frame(string = .) %>%
  rename("Mean (sd)" = string) %>%
  cbind(p, n, fn_baseline_str, .) %>%
  tibble() %>%
  xtable(caption = "False \\textbf{negatives} per sample - Max/Min Scaled X and Z")

rm(min_max_XZ_simulation_results)
```

```{r print-mm-only-xtable, results='asis', echo=FALSE}
print(fp_xtable_mmZ, 
      comment=FALSE, 
      include.rownames = FALSE,
      table.placement = "H")
print(fn_xtable_mmZ, 
      comment=FALSE, 
      include.rownames = FALSE,
      table.placement = "H")
print(fp_xtable_mmX, 
      comment=FALSE, 
      include.rownames = FALSE,
      table.placement = "H")
print(fn_xtable_mmX, 
      comment=FALSE, 
      include.rownames = FALSE,
      table.placement = "H")
print(fp_xtable_mmXZ, 
      comment=FALSE, 
      include.rownames = FALSE,
      table.placement = "H")
print(fn_xtable_mmXZ, 
      comment=FALSE, 
      include.rownames = FALSE,
      table.placement = "H")
```

### Max-Min + Normalization Feature Scaling

```{r min-max-norm-sims, include=FALSE, cache = TRUE}
load("minmax_norm_Z_sim.Rda")

fp_xtable_mmnorm_Z = min_max_norm_Z_simulation_results %>%
  map(function(x)
    map_dbl(x, pluck, "FP_n")
  ) %>% 
  map_chr(meanAndSdStr) %>% 
  data.frame(string = .) %>%
  rename("Mean (sd)" = string) %>%
  cbind(p, n, fp_baseline_str, .) %>%
  tibble() %>%
  xtable(caption = "False \\textbf{positives} per sample - Max/Min Scaled then Normalized Z, Centered X")

fn_xtable_mmnorm_Z = min_max_norm_Z_simulation_results %>%
  map(function(x)
    map_dbl(x, pluck, "FN_n")
  ) %>% 
  map_chr(meanAndSdStr) %>% 
  data.frame(string = .) %>%
  rename("Mean (sd)" = string) %>%
  cbind(p, n, fn_baseline_str, .) %>%
  tibble() %>%
  xtable(caption = "False \\textbf{negatives} per sample - Max/Min Scaled then Normalized Z, Centered X")

rm(min_max_norm_Z_simulation_results)

load("minmax_norm_X_sim.Rda")

fp_xtable_mmnorm_X = min_max_norm_X_simulation_results %>%
  map(function(x)
    map_dbl(x, pluck, "FP_n")
  ) %>% 
  map_chr(meanAndSdStr) %>% 
  data.frame(string = .) %>%
  rename("Mean (sd)" = string) %>%
  cbind(p, n, fp_baseline_str, .) %>%
  tibble() %>%
  xtable(caption = "False \\textbf{positives} per sample - Normalized Z, Max/Min Scaled then Centered X")

fn_xtable_mmnorm_X = min_max_norm_X_simulation_results %>%
  map(function(x)
    map_dbl(x, pluck, "FN_n")
  ) %>% 
  map_chr(meanAndSdStr) %>% 
  data.frame(string = .) %>%
  rename("Mean (sd)" = string) %>%
  cbind(p, n, fn_baseline_str, .) %>%
  tibble() %>%
  xtable(caption = "False \\textbf{negatives} per sample - Normalized Z, Max/Min Scaled then Centered X")

rm(min_max_norm_X_simulation_results)

load("minmax_norm_XZ_sim.Rda")

fp_xtable_mmnorm_XZ = min_max_norm_XZ_simulation_results %>%
  map(function(x)
    map_dbl(x, pluck, "FP_n")
  ) %>% 
  map_chr(meanAndSdStr) %>% 
  data.frame(string = .) %>%
  rename("Mean (sd)" = string) %>%
  cbind(p, n, fp_baseline_str, .) %>%
  tibble() %>%
  xtable(caption = "False \\textbf{positives} per sample - Max/Min Scaled then Centered X and then Normalized Z")

fn_xtable_mmnorm_XZ = min_max_norm_XZ_simulation_results %>%
  map(function(x)
    map_dbl(x, pluck, "FN_n")
  ) %>% 
  map_chr(meanAndSdStr) %>% 
  data.frame(string = .) %>%
  rename("Mean (sd)" = string) %>%
  cbind(p, n, fn_baseline_str, .) %>%
  tibble() %>%
  xtable(caption = "False \\textbf{negatives} per sample - Max/Min Scaled then Centered X and then Normalized Z")

rm(min_max_norm_XZ_simulation_results)
```

```{r print-mm-norm-xtable, results='asis', echo=FALSE}
print(fp_xtable_mmnorm_Z, 
      comment=FALSE, 
      include.rownames = FALSE,
      table.placement = "H")
print(fn_xtable_mmnorm_Z, 
      comment=FALSE, 
      include.rownames = FALSE,
      table.placement = "H")
print(fp_xtable_mmnorm_X,
      comment=FALSE,
      include.rownames = FALSE,
      table.placement = "H")
print(fn_xtable_mmnorm_X, 
      comment=FALSE, 
      include.rownames = FALSE,
      table.placement = "H")
print(fp_xtable_mmnorm_XZ, 
      comment=FALSE, 
      include.rownames = FALSE,
      table.placement = "H")
print(fn_xtable_mmnorm_XZ, 
      comment=FALSE, 
      include.rownames = FALSE,
      table.placement = "H")
```

## Multiple Prior Inclusion Probabilities

### Oracle or Informative Prior

```{r oracle-sims, include=FALSE, cache = TRUE}
load("oracle_results.Rda")

fp_xtable_oracle = oracle_results %>%
  map(function(x)
    map_dbl(x, pluck, "FP_n")
  ) %>% 
  map_chr(meanAndSdStr) %>% 
  data.frame(string = .) %>%
  rename("Mean (sd)" = string) %>%
  cbind(p, n, fp_baseline_str, .) %>%
  tibble() %>%
  xtable(caption = "False \\textbf{positives} per sample - Multiple PIP with Oracle Clustering")

fn_xtable_oracle = oracle_results %>%
  map(function(x)
    map_dbl(x, pluck, "FN_n")
  ) %>% 
  map_chr(meanAndSdStr) %>% 
  data.frame(string = .) %>%
  rename("Mean (sd)" = string) %>%
  cbind(p, n, fn_baseline_str, .) %>%
  tibble() %>%
  xtable(caption = "False \\textbf{negatives} per sample - Multiple PIP with Oracle Clustering")

rm(oracle_results)
```

```{r print-oracle-xtable, results='asis', echo=FALSE}
print(fp_xtable_oracle, 
      comment=FALSE, 
      include.rownames = FALSE,
      table.placement = "H")
print(fn_xtable_oracle, 
      comment=FALSE, 
      include.rownames = FALSE,
      table.placement = "H")
```

### Prior Inclusion through Covariate Clustering

### Prior Inclusion at the Individual Level
