---
title: "Testing out scaling"
author: "cool people"
format: pdf
editor: visual
---

```{r setup, include = FALSE}
library(covdepGE)
library(tidyverse)
library(purrr)
library(Matrix)
library(xtable)
```

## Get a baseline (centered X, centered/scaled Z)

```{r baseline-sims}
# Load in simulation studies

# Not doing the p100 n300 case since a single simulation
# requires over 16 hours on the cluster and many simulations
# need to be done

p = c(5, 15, 25, 50)
n = c(90, 90, 150, 150)
objects_strings = c(
  "simulation_study//p5_n90//res_p5_n90_covdepGE_20220908_215120.Rda",
  "simulation_study//p15_n90//res_p15_n90_covdepGE_20220908_215229.Rda",
  "simulation_study//p25_n150//res_p25_n150_covdepGE_20220825_121750.Rda",
  "simulation_study//p50_n150//res_p50_n150_covdepGE_20220825_090326.Rda"
  # "simulation_study//p100_n300//res_p100_n300_covdepGE_20220824_084919.Rda"
)

results_original = list()
for(sim in 1:length(objects_strings)) {
  load(objects_strings[sim])
  results_original[[sim]] = results
  rm(results)
}
sim_names_original = paste0("p", p, "_n", n)
results_original = set_names(results_original, sim_names_original)
```

Calculate mean FP/n and FN/n

```{r fp-per-samp-baseline, results='asis'}
false_positives_baseline = results_original %>%
  map(function(x)
    map_dbl(x, pluck, "FP_n")
  )
false_negatives_baseline = results_original %>%
  map(function(x)
    map_dbl(x, pluck, "FN_n")
  )

false_positives_baseline %>% 
  map_dfr(summary) %>% 
  cbind(p, n, .) %>%
  tibble() %>%
  xtable(caption = "False positives per sample - Normalized Z, Centered X")

false_negatives_baseline %>% 
  map_dfr(summary) %>% 
  cbind(p, n, .) %>%
  tibble() %>%
  xtable("False negatives per sample - Normalized Z, Centered X")

```

Goal: reduce mean FP/n (and either reduce or keep constant FN/n)

# Data generation

```{r data-gen, cache = TRUE}
set.seed(12345)
n_trials = 100

simulation_list = map2(n, p, function(n,p){
  nj = n %/% 3
  replicate(n_trials, generateData(p, nj, nj, nj), F)
})
```

```{r sim-functions, include=FALSE}
eval_est <- function(est, true){

  # get n
  n <- dim(est)[3]

  # get true number of edges and non-edges
  num_edge <- sum(true, na.rm = T)
  num_non <- sum(true == 0, na.rm = T)

  # calculate sensitivity, specificity, etc.
  true_edge <- sum(est == 1 & true == 1, na.rm = T)
  false_edge <- sum(est == 1 & true == 0, na.rm = T)
  true_non <- sum(est == 0 & true == 0, na.rm = T)
  false_non <- sum(est == 0 & true == 1, na.rm = T)
  sens <- true_edge / num_edge
  spec <- true_non / num_non

  list(sens = sens, spec = spec, TP_n = true_edge / n, FP_n = false_edge / n,
       TN_n = true_non / n, FN_n = false_non / n)
}

# function to turn an array into a list of sparse matrices
sp.array <- function(arr, n){
  lapply(1:n, function(l) Matrix::Matrix(arr[ , , l], sparse = T))
}

covdepGE.eval <- function(X, Z, true, n_workers, transforms = TRUE){

  start <- Sys.time()

  # get dimensions of the data and fit covdepGE
  n <- nrow(X)
  p <- ncol(X)
  if(transforms){
    out <- covdepGE(X = X,
                  Z = Z,
                  parallel = T,
                  num_workers = n_workers)
  } else {
    out <- covdepGE(X = X,
                  Z = Z,
                  parallel = T,
                  num_workers = n_workers,
                  center_X = FALSE,
                  scale_Z = FALSE)
  }
  

  # record time and get the array of graphs
  out$time <- as.numeric(Sys.time() - start, units = "secs")
  out$str <- array(unlist(out$graphs$graphs), dim = c(p, p, n))

  # covert the unique graphs to a sparse array
  out$unique_graphs <- out$graphs$unique_graphs
  for (k in 1:length(out$unique_graphs)){
    out$unique_graphs[[k]]$graph <- Matrix::Matrix(
      out$unique_graphs[[k]]$graph, sparse = T)
  }

  # remove large objects, put the unique graphs back in the graphs sublist
  out$variational_params <- out$graphs <- out$weights <- NULL
  out$graphs$unique_graphs <- out$unique_graphs
  out$unique_graphs <- NULL

  # get performance, convert graphs to a sparse array, and return
  perf <- eval_est(out$str, true)
  out[names(perf)] <- perf
  out$str <- sp.array(out$str, n)
  message("\ncovdepGE complete ", Sys.time(), "\n")
  out
}

simulation_func = function(n_trials, 
                           data_list, 
                           num_workers, 
                           normalize) {
  
  results <- vector("list", n_trials)
  names(results) <- c(paste0("trial", 1:n_trials))
  pb <- txtProgressBar(0, n_trials, style = 3)
  
  
  for (j in 1:n_trials) {

  # record the time the trial started
  trial_start <- Sys.time()

  # get the data
  data <- data_list[[j]]
    n = nrow(data$X)
    p = ncol(data$X)

  # convert the true precision to an array and then to a graph; mask diagonal
  prec <- array(unlist(data$true_precision), c(p, p, n))
  graph <- (prec != 0) * 1 + replicate(n, diag(rep(NA, p)) * 1)

  # fit covdepGE
  out_covdepGE <- tryCatch(covdepGE.eval(X = data$X,
                                         Z = data$Z,
                                         true = graph,
                                         n_workers = num_workers,
                                         transforms = normalize),
                           error = function(e) list(error = e))
  if (!is.null(out_covdepGE$error)) message(out_covdepGE$error)

  # save the trial and update the progress bar
  results[[j]] <- out_covdepGE
  setTxtProgressBar(pb, j)
  }
  return(results)
}
```

```{r min-max-funcs}

max_min_scale = function(X) { # Scale each column by max-min
  # Columnwise; subtract min and divide by resulting max
  if(!is.matrix(X)) { # for vectors
    X = as.matrix(X)
  } 
  p = ncol(X)
  n = nrow(X)
  # faster with max.col(X) and max.col(-X)
  mins = as.vector(apply(X, 2, min)) 
  scaled_X = t(t(X)-mins)
  maxs = as.vector(apply(scaled_X, 2, max))
  scaled_X = t(t(scaled_X)/maxs)
  return(list(scaled_X = scaled_X, add_invs = mins, mult_invs = maxs))
}

max_min_unscale = function(output) {
  t(t(output$scaled_X)*output$mult_invs + output$add_invs)
}
```

# Raw performance (no center/scaling)

# Test max-min scaling

We'll try 3 situations; scaling both X and Z, scaling only Z, and scaling only X

```{r try-min-max-scaling, warning=FALSE, message=FALSE, cache = TRUE}
min_max_simulation_list = map(simulation_list, function(setup){
  mm_X_data_list = map(setup, function(sim) {
    output = max_min_scale(sim$X)
    sim$X = output$scaled_X
    sim$scaleoutX = output
    sim
  })
  mm_Z_data_list = map(setup, function(sim) {
    output = max_min_scale(sim$Z)
    sim$Z = output$scaled_X
    sim$scaleoutZ = output
    sim
  })
  mm_XZ_data_list = map(setup, function(sim) {
    output = max_min_scale(sim$X)
    sim$X = output$scaled_X
    sim$scaleout = output
    output2 = max_min_scale(sim$Z)
    sim$Z = output2$scaled_X
    sim$scaleoutZ = output2
    sim
  })
  list(mm_X_data_list, mm_Z_data_list, mm_XZ_data_list)
})
```

```{r run-expensive-things, cache = TRUE, warning=FALSE, message=FALSE, eval=FALSE}
num_workers <- parallel::detectCores() - 8
doParallel::registerDoParallel(cores = num_workers)

min_max_X_simulation_results = min_max_simulation_list %>% map(~pluck(.x, 1)) %>%
  map(function(setup){
    simulation_func(n_trials, setup, num_workers, normalize = FALSE)
  })
  
save(min_max_X_simulation_results, file = "minmax_X_sim.Rda")

min_max_Z_simulation_results = min_max_simulation_list %>% map(~pluck(.x, 2)) %>%
  map(function(setup){
    simulation_func(n_trials, setup, num_workers, normalize = FALSE)
  })
  
save(min_max_Z_simulation_results, file = "minmax_Z_sim.Rda")

min_max_XZ_simulation_results = min_max_simulation_list %>% map(~pluck(.x, 3)) %>%
  map(function(setup){
    simulation_func(n_trials, setup, num_workers, normalize = FALSE)
  })
  
save(min_max_XZ_simulation_results, file = "minmax_XZ_sim.Rda")
```

```{r read-results, echo=FALSE, cache=TRUE}
load("minmax_X_sim.Rda")
load("minmax_Z_sim.Rda") 
load("minmax_XZ_sim.Rda")
```

```{r max-min-scaling-results, results='asis', echo=FALSE}
min_max_Z_simulation_results %>%
  map(function(x)
    map_dbl(x, pluck, "FP_n")
  ) %>% 
  map_dfr(summary) %>% 
  cbind(p, n, .) %>%
  tibble() %>%
  xtable(caption = "False positives per sample - Max/Min Scaled Z")

min_max_Z_simulation_results %>%
  map(function(x)
    map_dbl(x, pluck, "FN_n")
  ) %>% 
  map_dfr(summary) %>% 
  cbind(p, n, .) %>%
  tibble() %>%
  xtable(caption = "False negatives per sample - Max/Min Scaled Z")
```

## Test Max-min + Normalization

First do a max-min transform to scale, then do the z-transform (or mean 0 center transform in the case of X)

```{r run-expensive-norm-things, cache = TRUE, warning=FALSE, message=FALSE, eval=FALSE}
num_workers <- parallel::detectCores() - 8
doParallel::registerDoParallel(cores = num_workers)

min_max_norm_X_simulation_results = min_max_simulation_list %>% map(~pluck(.x, 1)) %>%
  map(function(setup){
    simulation_func(n_trials, setup, num_workers, normalize = TRUE)
  })
  
save(min_max_norm_X_simulation_results, file = "minmax_norm_X_sim.Rda")

min_max_norm_Z_simulation_results = min_max_simulation_list %>% map(~pluck(.x, 2)) %>%
  map(function(setup){
    simulation_func(n_trials, setup, num_workers, normalize = TRUE)
  })
  
save(min_max_norm_Z_simulation_results, file = "minmax_norm_Z_sim.Rda")

min_max_norm_XZ_simulation_results = min_max_simulation_list %>% map(~pluck(.x, 3)) %>%
  map(function(setup){
    simulation_func(n_trials, setup, num_workers, normalize = TRUE)
  })
  
save(min_max_norm_XZ_simulation_results, file = "minmax_norm_XZ_sim.Rda")
```

```{r load-norm-mm-res, echo=FALSE}
load("minmax_norm_X_sim.Rda")
load("minmax_norm_Z_sim.Rda") 
load("minmax_norm_XZ_sim.Rda")
```



```{r max-min-norm-scaling-results, results='asis', echo=FALSE}
min_max_norm_X_simulation_results %>%
  map(function(x)
    map_dbl(x, pluck, "FP_n")
  ) %>% 
  map_dfr(summary) %>% 
  cbind(p, n, .) %>%
  tibble() %>%
  xtable(caption = "False positives per sample - Max/Min Scaled X and Normalization")

min_max_norm_X_simulation_results %>%
  map(function(x)
    map_dbl(x, pluck, "FN_n")
  ) %>% 
  map_dfr(summary) %>% 
  cbind(p, n, .) %>%
  tibble() %>%
  xtable(caption = "False negatives per sample - Max/Min Scaled X and Normalization")

min_max_norm_Z_simulation_results %>%
  map(function(x)
    map_dbl(x, pluck, "FP_n")
  ) %>% 
  map_dfr(summary) %>% 
  cbind(p, n, .) %>%
  tibble() %>%
  xtable(caption = "False positives per sample - Max/Min Scaled Z and Normalization")

min_max_norm_Z_simulation_results %>%
  map(function(x)
    map_dbl(x, pluck, "FN_n")
  ) %>% 
  map_dfr(summary) %>% 
  cbind(p, n, .) %>%
  tibble() %>%
  xtable(caption = "False negatives per sample - Max/Min Scaled Z and Normalization")

min_max_norm_XZ_simulation_results %>%
  map(function(x)
    map_dbl(x, pluck, "FP_n")
  ) %>% 
  map_dfr(summary) %>% 
  cbind(p, n, .) %>%
  tibble() %>%
  xtable(caption = "False positives per sample - Max/Min Scaled X and Z and Normalization")

min_max_norm_XZ_simulation_results %>%
  map(function(x)
    map_dbl(x, pluck, "FN_n")
  ) %>% 
  map_dfr(summary) %>% 
  cbind(p, n, .) %>%
  tibble() %>%
  xtable(caption = "False negatives per sample - Max/Min Scaled X and Z and Normalization")
```






